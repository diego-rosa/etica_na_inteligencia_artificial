<!DOCTYPE html>
<html lang="pt-BR">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ética na Inteligência Artificial</title>
    <link rel="icon" href="imagens/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&family=Space+Mono:wght@400;700&display=swap"
        rel="stylesheet">
</head>
<body>
    <header class="hero">
        <div class="container">
            <p class="subtitle">Ética na Tecnologia</p>
            <h1>As <span class="highlight">Letras Miúdas</span> da tecnologia</h1>
            <p class="intro">Uma reflexão profunda aos princípios éticos da Inteligência Artificial (IA) e os preços que pagamos por ela.
            </p>
            <a href="#content" class="btn">Começar a leitura</a>
        </div>
    </header>

    <main id="content">
        <section class="bio">
            <div class="container">
                <h2>Conscientização: Ética na Inteligência Artificial</h2>
                <div class="bio-content">
                    <div class="bio-text">
                        <p>O avanço acelerado da IA transformou profundamente a sociedade,
                            influenciando decisões políticas, empresariais e individuais. À medida que algoritmos
                            assumem papéis cada vez mais complexos, torna-se essencial refletir sobre os impactos
                            éticos, sociais e humanos dessas tecnologias.</p>

                        <p>Esta página tem como propósito promover consciência crítica, estimular o uso
                        responsável da IA e difundir conhecimento científico sobre ética tecnológica.</p>

                        <div class="story-card">
                            <h3>Objetivos</h3>
                            <ul>
                                <li>Refletir criticamente sobre dilemas éticos da IA</li>
                                <li>Desenvolver consciência sobre impactos sociais e riscos</li>
                                <li>Promover a conscientização sobre problemáticas éticas que envolvem tecnologia</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="topic" id="bias">
            <div class="container">
                <div class="topic-header">
                    <h2>Princípios Fundamentais</h2>
                </div>
                <span class="topic-number">01</span>
                <h3>Transparência</h3>
                <p>Sistemas de IA devem ser compreensíveis, auditáveis e fornecer clareza sobre como decisões são
                    tomadas. Usuários precisam saber quando estão interagindo com algoritmos e como seus dados são
                    utilizados.</p>
            </div>
            <div class="container">
                <span class="topic-number">02</span>
                <h3>Privacidade e Proteção de Dados</h3>
                <p>O tratamento de dados deve respeitar limites éticos e legais. Privacidade deve ser garantida desde a
                    concepção, reforçando o direito do usuário sobre suas informações.</p>
            </div>

            <div class="container">
                <span class="topic-number">03</span>
                <h3>Justiça e Não Discriminação</h3>
                <p>Modelos de IA devem ser avaliados continuamente para evitar vieses que causem discriminação por raça,
                    gênero, idade, classe social ou outros critérios sensíveis.
            </div>

            <div class="container">
                <span class="topic-number">04</span>
                <h3>Responsabilidade</h3>
                <p>Desenvolvedores, empresas e instituições devem assumir responsabilidade por impactos negativos,
                    falhas ou danos causados por sistemas automatizados.</p>
            </div>

            <div class="container">
                <span class="topic-number">05</span>
                <h3>Segurança</h3>
                <p>Tecnologias de IA precisam de mecanismos robustos para prevenir ataques, manipulações, usos
                    mal-intencionados ou perda de controle.</p>
            </div>

            <div class="container">
                <span class="topic-number">06</span>
                <h3>Regulação</h3>
                <p>A inovação não acontece sem você minimamente respeitar os limites éticos e respeitar os cidadãos. Os
                    direitos das pessoas devem vir primeiro.</p>
            </div>

            <div class="container">
                <span class="topic-number">07</span>
                <h3>Benefício Social</h3>
                <p>A IA deve contribuir para o bem-estar coletivo, democratizar o acesso ao conhecimento e reduzir
                    desigualdades, garantindo que seu avanço seja acompanhado de valores humanos.</p>
            </div>
        </section>

            <section class="topic" id="bias">
            <div class="container">
                <div class="topic-header">
                    <h2>Compromissos para uma Sociedade Digital Ética</h2>
                </div>
                <h3>Para desenvolvedores</h3>
                <ul>
                    <li>Criar sistemas explicáveis e testáveis</li>
                    <li>Reduzir vieses e promover equidade algorítmica</li>
                    <li>Priorizar privacidade e segurança desde o design</li>
                </ul><br>
                <h3>Para empresas</h3>
                <ul>
                    <li>Criar políticas de governança e ética em IA</li>
                    <li>Publicar relatórios de impacto e responsabilidade</li>
                    <li>Garantir práticas transparentes e não abusivas</li>
                </ul><br>
                <h3>Para usuários</h3>
                <ul>
                    <li>Consumir tecnologia de maneira consciente</li>
                    <li>Questionar algoritmos que influenciam decisões</li>
                    <li>Proteger dados pessoais e denunciar abusos</li>
                </ul><br>
                <h3>Para governos</h3>
                <ul>
                    <li>Desenvolver leis claras e atualizadas sobre IA</li>
                    <li>Incentivar pesquisas éticas e inovadoras</li>
                    <li>Fiscalizar aplicações de IA de alto impacto</li>
                </ul>
            </div>
        </section>

        <section class="interactive">
            <div class="container">
                <h2>Chamado à Ação</h2>
                <p>A ética na IA é um compromisso coletivo. Cada cidadão, estudante, profissional e instituição tem um papel essencial na construção de um ecossistema digital mais justo, seguro e transparente. O futuro da inteligência artificial depende das escolhas que fazemos hoje, e este manifesto convida todos a participar dessa construção.</p>
            </div>
        </section>
        
        <section class="interactive">
            <div class="container">
                <h2>O que você pode fazer?</h2>
                <p>Mesmo que no nosso dia a dia utilizemos as ferramentas tecnológicas, devemos manter uma relação
                    "mediada pelo medo" com a tecnologia. Como o próprio título da página sugere, devemos nos questionar
                    o que estamos fazendo e como estamos nos beneficiando, devemos ler as letras miúdas das tecnologias
                    impostas.
                <div class="action-grid">
                    <div class="action-item">
                        <h4>Leia as letras miúdas</h4>
                        <p>Entenda o que você está aceitando ao clicar em "Concordo".</p>
                    </div>
                    <div class="action-item">
                        <h4>Questione a necessidade</h4>
                        <p>Seu condomínio realmente precisa de reconhecimento facial?</p>
                    </div>
                    <div class="action-item">
                        <h4>Exija transparência</h4>
                        <p>Pergunte onde seus dados estão sendo armazenados.</p>
                    </div>
                </div>
                <button id="fine-print-btn" class="btn-outline">Ler as "Letras Miúdas" deste site</button>
            </div>
        </section>

        <div id="fine-print-modal" class="modal hidden">
            <div class="modal-content">
                <span class="close">&times;</span>
                <h3>Termos de Reflexão</h3>
                <p>Ao acessar este conhecimento, você concorda em:</p>
                <ul>
                    <li>Não assumir que a tecnologia é neutra.</li>
                    <li>Questionar quem lucra com seus dados.</li>
                    <li>Lutar por uma tecnologia antirracista e inclusiva.</li>
                </ul>
                <p class="signature">Assinado: Sua Consciência Crítica</p>
            </div>
        </div>
    </main>
    <section class="interactive">
            <div class="container">
                <h2>Cases Reais</h2><br>
                <h3>COMPAS: viés racial e injustiça no sistema de justiça criminal</h3>
                <ul>
                    <li>O COMPAS é um algoritmo usado para estimar o risco de reincidência criminal de réus nos EUA. Estudos mostraram que ele tende a classificar réus negros como “alto risco” de reincidência com muito mais frequência do que réus brancos — mesmo quando os antecedentes criminais são semelhantes.</li><br>
                    <li>Críticas apontam que, além da discriminação racial, há falta de transparência: os critérios de decisão do algoritmo não são claros, impedindo que réus e advogados verifiquem como as pontuações foram atribuídas. Isso viola princípios de justiça e responsabilidade.</li><br>
                    <li>O uso de COMPAS em decisões judiciais (liberdade condicional, penas, fianças etc.) revela como sistemas de IA podem reforçar desigualdades estruturais — numa área tão sensível quanto a justiça penal.</li><br>
                </ul>
            </div><br>
            <div class="container">
                <h3>Algoritmo de Recrutamento da Amazon</h3>
                <ul>
                    <li>O sistema, desenvolvido internamente por volta de 2014, foi um projeto de pesquisa para automatizar a busca por talentos, analisando currículos enviados ao longo de uma década.</li><br>
                    <li>Problema Ético Principal: Viés Algorítmico de Gênero. O algoritmo penalizava candidaturas que continham termos associados ao gênero feminino (como "mulher" ou a participação em "clube de xadrez feminino"). Ele também rebaixava graduandos de colégios apenas para mulheres.</li><br>
                    <li>Causa Técnica (sob a ótica do Processamento Profundo): O modelo de processamento de linguagem natural (NLP), treinado com os currículos históricos da empresa (em sua maioria de homens), não aprendeu "competência", mas sim a correlação estatística entre um perfil de candidato bem-sucedido e o gênero masculino. Ele identificou padrões linguísticos e experiências historicamente associadas a homens como "ótimos indicadores" de adequação ao cargo.</li><br>
                    <li>Consequência e Desfecho: A Amazon tentou ajustar o algoritmo para ser neutro em relação a termos específicos, mas concluiu que não poderia garantir a eliminação de outros vieses sutis. O projeto foi abandonado e nunca foi usado para avaliação real de candidatos.</li><br>
                </ul>
            </div>
        </section>  

        <section class="interactive">
            <div class="container">
                <h2>Ferramentas utilizadas</h2><br>
                <h3>ChatGPT</h3><br>
                <p>O ChatGPT foi utilizado para:</p>
                <ul>
                    <li>Pesquisar informações sobre ética na inteligência artificial</li>
                    <li>Elaborar explicações conceituais</li>
                    <li>Integrar os objetivos da atividade</li>
                    <li>Revisar, organizar e padronizar o texto final</li>
                </ul><br>
                <p>Sua função principal foi criar e desenvolver conteúdo textual com clareza, coerência e rigor conceitual.</p>

                <h3>Gemini</h3><br>
                <p>O modelo Gemini foi utilizado para:</p>
                <ul>
                    <li>Pesquisar conteúdo complementar sobre ética em IA</li>
                    <li>Comparar perspectivas e reforçar pontos críticos do tema</li>
                    <li>Ampliar o repertório com visões alternativas e atualizadas</li>
                </ul><br>
                <p>O Gemini atuou como uma segunda linha de pesquisa, trazendo diversidade e riqueza de informações.</p>

                <h3>DeepSeek</h3><br>
                <p>A ferramenta DeepSeek foi usada para:</p>
                <ul>
                    <li>Levantar cases reais de problemas éticos envolvendo IA</li>
                    <li>Buscar fontes verificáveis, notícias e estudos relacionados</li>
                    <li>Apoiar a construção da seção de estudos de caso do trabalho</li>
                </ul><br>
                <p>O principal papel do DeepSeek foi pesquisar eventos reais com embasamento, garantindo credibilidade ao trabalho.</p>

                <h3>NotebookLM</h3><br>
                <p>O NotebookLM foi responsável por:</p>
                <ul>
                    <li>Organizar o material reunido nas diferentes pesquisas</li>
                    <li>Reunir todas as informações em uma estrutura coerente</li>
                    <li>Sugerir um modelo de manifesto baseado nos dados coletados</li>
                    <li>Ajudar a manter consistência entre as seções do trabalho</li>
                </ul><br>
                <p>Seu papel principal foi sintetizar e estruturar a informação, funcionando como um organizador inteligente.</p>

                <h3>Antigravity</h3><br>
                <p>A ferramenta Antigravity foi utilizada para:</p>
                <ul>
                    <li>Criar uma página web relacionada ao manifesto</li>
                    <li>Construir um protótipo ou layout digital do conteúdo</li>
                    <li>Organizar visualmente as seções do manifesto de forma acessível e moderna</li>
                </ul><br>
                <p>Seu papel foi criar uma interface visualmente atraente e funcional para o conteúdo, garantindo que o manifesto fosse acessível e moderno.</p>
            </div>
        </section>
        
        <section class="interactive">
            <div class="container">
                <h2>Fontes utilizadas nos Cases</h2><br>
                <p>Sistema de algoritmo que determina pena de condenados cria polêmica nos EUA</p>
                <a href="https://www.bbc.com/portuguese/brasil-37677421">https://www.bbc.com/portuguese/brasil-37677421</a>
            </div><br>
            <div class="container">
                <p>Amazon desiste de ferramenta secreta de recrutamento</p>
                <a href="https://forbes.com.br/last/2018/10/amazon-desiste-de-ferramenta-secreta-de-recrutamento/">https://forbes.com.br/last/2018/10/amazon-desiste-de-ferramenta-secreta-de-recrutamento/</a>
            </div>
        </section>
    <footer>
        <div class="container">
            <p class="copyright">&copy; Copyright - Desenvolvido por <strong>Diego José Rosa da Silva</strong></p>
        </div>
    </footer>
    <script src="script.js"></script>
</body>
</html>